{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kd7ynyNPrsrj",
        "outputId": "f5a7bebe-3049-45fb-a23c-4b6dde245365"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m71.7/76.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2023.11.17)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.0\n"
          ]
        }
      ],
      "source": [
        "#install openai on colab (We are using old version as the new version was released on Nov 8, 2023)\n",
        "!pip install openai==0.28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-PzBwWpt_BR",
        "outputId": "519d0a83-8d2d-42a0-a26f-9951c1857824"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"index\": 0,\n",
            "  \"message\": {\n",
            "    \"role\": \"assistant\",\n",
            "    \"content\": \"Deep Learning works by using artificial neurons or perceptrons, which are inspired by the neurons in our brain. These neurons fire off signals when they recognize patterns in the data they are trained on. Initially, they recognize simple patterns, but when combined in a neural network, they can recognize more complex patterns. This process of recognizing patterns is called Deep Learning. It can be used in various applications such as analyzing stock market data, diagnosing diseases from medical images, and understanding spoken language.\"\n",
            "  },\n",
            "  \"finish_reason\": \"stop\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import openai  # Ensure the OpenAI Python package is installed\n",
        "openai.api_key = 'your api key'\n",
        "\n",
        "# This is the function that will send a prompt to the OpenAI API and get a response.\n",
        "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    # 'messages' is a list that contains a dictionary representing the user's message.\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "    # This line sends a request to the OpenAI API.\n",
        "    # 'model' specifies which AI model to use.\n",
        "    # 'messages' contains the conversation history.\n",
        "    # 'temperature' influences the randomness of the AI's responses (0 is less random, 1 is more random).\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0.5,\n",
        "    )\n",
        "\n",
        "    # This line extracts the AI's message from the response and returns it.\n",
        "    return response.choices[0] #.message[\"content\"]\n",
        "\n",
        "# This is the text that we want to summarize.\n",
        "text = \"Grandma! Do you remember when we used to play the game of recognizing shapes when I was a child? \\\n",
        " You would show me a card with a shape and I would tell you if it's a circle, square, triangle and so on. Over time,\\\n",
        "  my brain learned to recognize these shapes no matter their size or color.  Deep Learning works quite similarly.  \\\n",
        "  The building block of Deep Learning is something called a 'neuron' or 'perceptron', inspired by the neurons in our brain.\\\n",
        "   Just like how our neurons fire electrical signals when they recognize a shape, these computer 'neurons' fire off their \\\n",
        "    own signals when they recognize certain patterns in the data they are trained on.  At first, these artificial neurons\\\n",
        "     might only recognize very simple patterns, like a straight line or a curve. This is similar to how I first learned\\\n",
        "      to recognize shapes - I started by recognizing simple ones like a circle or square.  But if you combine many of these \\\n",
        "       artificial neurons together, they can start recognizing more complex patterns, much like how I could eventually \\\n",
        "        recognize more complex shapes like a star or a heart. This network of artificial neurons is called a neural network,\\\n",
        "         and the process of them learning to recognize patterns is what we call Deep Learning. So, in short, Deep Learning is a \\\n",
        "         bit like teaching a computer to recognize shapes, but instead, it might be recognizing patterns in stock market data, \\\n",
        "          diagnosing diseases from medical images, understanding spoken language, and much more!\"\n",
        "\n",
        "# We form a prompt for summarization from the text.\n",
        "prompt = f\"Summarize the main points about how Deep Learning works text: {text} delimited by a newline.\\n\\n\"\n",
        "\n",
        "# We call our function with the summarization prompt and print out the summary.\n",
        "summary = get_completion(prompt)\n",
        "print(summary)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Os2x3bHRuBxX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
